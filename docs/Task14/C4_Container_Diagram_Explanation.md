# C4 Container Diagram - –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ

## üìã –û–±–∑–æ—Ä –¥–∏–∞–≥—Ä–∞–º–º—ã
**–§–∞–π–ª:** `C4_Container_Diagram.puml`  
**–£—Ä–æ–≤–µ–Ω—å:** Container (Level 2)  
**–¶–µ–ª—å:** –ü–æ–∫–∞–∑–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É UGC GraphQL Federation —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## üéØ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–≠—Ç–∞ –¥–∏–∞–≥—Ä–∞–º–º–∞ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä—É–µ—Ç **–∫–∞–∫ Task 14 —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤** –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã.

## üèóÔ∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å–∏—Å—Ç–µ–º—ã

### 1. GraphQL Gateway (Apollo Router)

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Ä–æ–ª—å
```yaml
# –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: router.yaml
federation_version: 2
supergraph:
  introspection: true
  
# Task 14: Performance optimizations –Ω–∞ gateway —É—Ä–æ–≤–Ω–µ
plugins:
  apollo.query_planner:
    experimental_plans_limit: 10000
  apollo.traffic_shaping:
    router:
      # Task 14: Rate limiting –Ω–∞ gateway —É—Ä–æ–≤–Ω–µ
      global_rate_limit:
        capacity: 1000
        interval: 60s
    subgraph:
      ugc-subgraph:
        # Task 14: Per-subgraph limits
        rate_limit:
          capacity: 500
          interval: 60s
```

#### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
```rust
// –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è gateway –ª–æ–≥–∏–∫–∏
impl GraphQLGateway {
    pub async fn route_query(&self, query: &str) -> Result<Response> {
        // Task 14: Query analysis –Ω–∞ gateway —É—Ä–æ–≤–Ω–µ
        let query_plan = self.planner.plan(query).await?;
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ complexity –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ subgraph
        if query_plan.complexity > self.config.max_complexity {
            return Err(QueryTooComplexError);
        }
        
        // –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –≤ UGC subgraph
        let subgraph_queries = query_plan.subgraph_queries;
        let responses = self.execute_subgraph_queries(subgraph_queries).await?;
        
        // –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤
        self.compose_response(responses).await
    }
}
```

### 2. UGC Subgraph Container

–≠—Ç–æ **–æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä Task 14**, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

#### 2.1 GraphQL Server

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/graphql/mod.rs
use async_graphql::{Schema, EmptySubscription};
use crate::performance::*;

pub type UGCSchema = Schema<QueryRoot, MutationRoot, EmptySubscription>;

pub async fn create_enhanced_schema(
    db_pool: PgPool,
    cache_manager: Arc<CacheManager>,
    dataloader_manager: Arc<DataLoaderManager>,
    query_analyzer: Arc<QueryComplexityAnalyzer>,
    rate_limiter: Arc<RateLimitService>,
) -> Result<UGCSchema> {
    
    let schema = Schema::build(
        QueryRoot::new(db_pool.clone()),
        MutationRoot::new(db_pool.clone()),
        EmptySubscription
    )
    // Task 14: –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ context
    .data(cache_manager)
    .data(dataloader_manager)
    .data(query_analyzer.clone())
    .data(rate_limiter.clone())
    
    // Task 14: Query complexity analysis extension
    .extension(QueryComplexityExtension::new(query_analyzer))
    
    // Task 14: Rate limiting extension
    .extension(RateLimitExtension::new(rate_limiter))
    
    // Task 14: Caching extension
    .extension(CacheExtension::new(cache_manager))
    
    // Task 14: DataLoader extension
    .extension(DataLoaderExtension::new(dataloader_manager))
    
    .finish();
    
    Ok(schema)
}
```

#### 2.2 DataLoader Service

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/service/dataloader.rs
pub struct DataLoaderManager {
    review_loader: Arc<ReviewDataLoader>,
    rating_loader: Arc<RatingDataLoader>,
    offer_loader: Arc<OfferDataLoader>,
    user_loader: Arc<UserDataLoader>,
}

impl DataLoaderManager {
    pub fn new(db_pool: PgPool, external_clients: ExternalClients) -> Self {
        Self {
            // Task 14: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö DataLoader'–æ–≤
            review_loader: Arc::new(ReviewDataLoader::new(
                ReviewRepository::new(db_pool.clone())
            )),
            rating_loader: Arc::new(RatingDataLoader::new(
                RatingRepository::new(db_pool.clone())
            )),
            offer_loader: Arc::new(OfferDataLoader::new(
                external_clients.offers_client
            )),
            user_loader: Arc::new(UserDataLoader::new(
                external_clients.users_client
            )),
        }
    }
    
    // Task 14: Request-scoped DataLoader instances
    pub fn create_request_context(&self) -> DataLoaderContext {
        DataLoaderContext {
            review_loader: self.review_loader.clone(),
            rating_loader: self.rating_loader.clone(),
            offer_loader: self.offer_loader.clone(),
            user_loader: self.user_loader.clone(),
        }
    }
}

// Task 14: Request-scoped context –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–µ–∫ –∫–µ—à–∞
pub struct DataLoaderContext {
    review_loader: Arc<ReviewDataLoader>,
    rating_loader: Arc<RatingDataLoader>,
    offer_loader: Arc<OfferDataLoader>,
    user_loader: Arc<UserDataLoader>,
}
```

#### 2.3 Cache Service

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/service/cache.rs
pub struct CacheService {
    manager: Arc<CacheManager>,
    invalidation_service: Arc<CacheInvalidationService>,
    warming_service: Arc<CacheWarmingService>,
}

impl CacheService {
    pub async fn new(redis_config: RedisConfig) -> Result<Self> {
        let manager = Arc::new(CacheManager::new(redis_config).await?);
        
        Ok(Self {
            manager: manager.clone(),
            // Task 14: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–µ—à–∞
            invalidation_service: Arc::new(
                CacheInvalidationService::new(manager.clone())
            ),
            // Task 14: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ–≤ –∫–µ—à–∞
            warming_service: Arc::new(
                CacheWarmingService::new(manager.clone())
            ),
        })
    }
    
    // Task 14: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å TTL
    pub async fn get_or_compute<T, F, Fut>(&self, 
        key: &str, 
        ttl: Duration,
        compute_fn: F
    ) -> Result<T> 
    where
        T: Serialize + DeserializeOwned + Clone + Send + 'static,
        F: FnOnce() -> Fut + Send,
        Fut: Future<Output = Result<T>> + Send,
    {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º L1 cache (memory)
        if let Some(cached) = self.manager.get_from_l1(key).await? {
            return Ok(cached);
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º L2 cache (Redis)
        if let Some(cached) = self.manager.get_from_l2(key).await? {
            // –û–±–Ω–æ–≤–ª—è–µ–º L1 cache
            self.manager.set_l1(key, &cached, ttl).await?;
            return Ok(cached);
        }
        
        // –í—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
        let computed = compute_fn().await?;
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±–∞ —É—Ä–æ–≤–Ω—è –∫–µ—à–∞
        self.manager.set_multi_level(key, &computed, ttl).await?;
        
        Ok(computed)
    }
}
```

#### 2.4 Query Analyzer

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/service/query_limits.rs
pub struct QueryAnalyzer {
    max_depth: u32,
    max_complexity: u32,
    field_complexity_map: HashMap<String, u32>,
    rate_limiter: Arc<RateLimitService>,
}

impl QueryAnalyzer {
    pub async fn analyze_and_validate(&self, 
        query: &str, 
        user_context: &UserContext
    ) -> Result<QueryValidationResult> {
        
        // Task 14: –ü–∞—Ä—Å–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏–∑ GraphQL query
        let document = parse_query(query)?;
        let mut analysis = QueryAnalysis::new();
        
        // –ê–Ω–∞–ª–∏–∑ –≥–ª—É–±–∏–Ω—ã
        self.analyze_depth(&document, &mut analysis)?;
        
        // –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        self.analyze_complexity(&document, &mut analysis)?;
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ rate limits
        let rate_limit_result = self.rate_limiter
            .check_user_limits(user_context.user_id)
            .await?;
        
        // Task 14: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        let validation_result = QueryValidationResult {
            is_valid: analysis.depth <= self.max_depth 
                && analysis.complexity <= self.max_complexity
                && rate_limit_result.allowed,
            depth: analysis.depth,
            complexity: analysis.complexity,
            estimated_cost: self.estimate_cost(&analysis),
            rate_limit_remaining: rate_limit_result.remaining,
            violations: analysis.violations,
        };
        
        Ok(validation_result)
    }
    
    // Task 14: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    fn calculate_field_complexity(&self, 
        field: &Field, 
        parent_type: &str
    ) -> u32 {
        let base_complexity = self.field_complexity_map
            .get(&format!("{}:{}", parent_type, field.name))
            .copied()
            .unwrap_or(1);
        
        // –£—á–∏—Ç—ã–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, first, limit)
        let multiplier = field.arguments.iter()
            .find(|(name, _)| name == "first" || name == "limit")
            .and_then(|(_, value)| value.as_i64())
            .unwrap_or(1) as u32;
        
        base_complexity * multiplier.min(100) // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π multiplier
    }
}
```

#### 2.5 Rate Limiter

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/service/rate_limit.rs
pub struct RateLimitService {
    redis_client: Arc<RedisCache>,
    default_limits: RateLimitConfig,
    user_specific_limits: Arc<RwLock<HashMap<UserId, RateLimitConfig>>>,
}

impl RateLimitService {
    pub async fn check_and_increment(&self, 
        user_id: UserId,
        query_complexity: u32
    ) -> Result<RateLimitResult> {
        
        let limits = self.get_user_limits(user_id).await;
        let window_key = format!("rate_limit:{}:{}", 
            user_id, 
            current_window_timestamp()
        );
        
        // Task 14: Sliding window rate limiting
        let current_usage = self.redis_client
            .get::<u32>(&window_key)
            .await?
            .unwrap_or(0);
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã —Å —É—á–µ—Ç–æ–º complexity
        let complexity_cost = (query_complexity as f64 / 100.0).ceil() as u32;
        let new_usage = current_usage + complexity_cost;
        
        if new_usage > limits.requests_per_minute {
            return Ok(RateLimitResult {
                allowed: false,
                remaining: 0,
                reset_time: next_window_timestamp(),
                retry_after: Duration::from_secs(60),
            });
        }
        
        // –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
        self.redis_client
            .set(&window_key, new_usage, Duration::from_secs(60))
            .await?;
        
        Ok(RateLimitResult {
            allowed: true,
            remaining: limits.requests_per_minute - new_usage,
            reset_time: next_window_timestamp(),
            retry_after: Duration::from_secs(0),
        })
    }
}
```

### 3. External Databases

#### 3.1 Redis Cache

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: src/database/redis.rs
pub struct RedisCluster {
    primary: redis::Client,
    replicas: Vec<redis::Client>,
    connection_pool: Pool<MultiplexedConnection>,
}

impl RedisCluster {
    pub async fn new(config: RedisClusterConfig) -> Result<Self> {
        let primary = redis::Client::open(config.primary_url)?;
        let replicas = config.replica_urls.into_iter()
            .map(|url| redis::Client::open(url))
            .collect::<Result<Vec<_>, _>>()?;
        
        // Task 14: Connection pooling –¥–ª—è Redis
        let connection_pool = Pool::builder()
            .max_size(config.max_connections)
            .min_idle(Some(config.min_connections))
            .build(primary.clone())
            .await?;
        
        Ok(Self { primary, replicas, connection_pool })
    }
    
    // Task 14: Read preference —Å fallback –Ω–∞ replicas
    pub async fn get<T>(&self, key: &str) -> Result<Option<T>>
    where T: DeserializeOwned 
    {
        // –ü—Ä–æ–±—É–µ–º primary
        match self.get_from_primary(key).await {
            Ok(result) => Ok(result),
            Err(_) => {
                // Fallback –Ω–∞ replicas
                for replica in &self.replicas {
                    if let Ok(result) = self.get_from_replica(replica, key).await {
                        return Ok(result);
                    }
                }
                Err(RedisError::AllNodesDown)
            }
        }
    }
}
```

#### 3.2 PostgreSQL Database

```sql
-- –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: Database schema optimizations
-- migrations/20240101_task14_performance.sql

-- Task 14: Connection pooling configuration
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '512MB';
ALTER SYSTEM SET effective_cache_size = '2GB';
ALTER SYSTEM SET work_mem = '16MB';
ALTER SYSTEM SET maintenance_work_mem = '256MB';

-- Task 14: Optimized indexes –¥–ª—è DataLoader patterns
CREATE INDEX CONCURRENTLY idx_reviews_dataloader_batch
ON reviews USING btree (id)
WHERE is_moderated = true;

CREATE INDEX CONCURRENTLY idx_reviews_offer_batch
ON reviews USING btree (offer_id, created_at DESC)
WHERE is_moderated = true
INCLUDE (id, content, rating, author_id);

-- Task 14: Partitioning –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
CREATE TABLE reviews_partitioned (
    LIKE reviews INCLUDING ALL
) PARTITION BY RANGE (created_at);

CREATE TABLE reviews_2024_q1 PARTITION OF reviews_partitioned
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');

-- Task 14: Materialized views –¥–ª—è expensive aggregations
CREATE MATERIALIZED VIEW offer_rating_summary AS
SELECT 
    offer_id,
    COUNT(*) as review_count,
    AVG(rating) as average_rating,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY rating) as median_rating
FROM reviews 
WHERE is_moderated = true
GROUP BY offer_id;

CREATE UNIQUE INDEX ON offer_rating_summary (offer_id);
```

## üîÑ Container Interactions

### 1. GraphQL Gateway ‚Üî UGC Subgraph

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: Gateway integration
impl SubgraphClient {
    pub async fn execute_query(&self, 
        query: &str, 
        variables: Variables
    ) -> Result<Response> {
        
        // Task 14: Request tracing –¥–ª—è performance monitoring
        let span = tracing::info_span!("subgraph_request", 
            subgraph = "ugc",
            query_hash = %hash_query(query)
        );
        
        async move {
            let request = GraphQLRequest {
                query: query.to_string(),
                variables,
                // Task 14: –ü–µ—Ä–µ–¥–∞–µ–º performance hints
                extensions: json!({
                    "performance": {
                        "enable_caching": true,
                        "enable_dataloader": true,
                        "max_complexity": 1000
                    }
                })
            };
            
            let response = self.http_client
                .post(&self.endpoint)
                .json(&request)
                .send()
                .await?;
            
            // Task 14: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ performance metrics
            self.metrics.record_subgraph_request_duration(
                start.elapsed()
            );
            
            response.json().await
        }.instrument(span).await
    }
}
```

### 2. UGC Subgraph Internal Communication

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: Internal service communication
impl GraphQLResolver {
    pub async fn resolve_field(&self, ctx: &Context<'_>) -> Result<FieldValue> {
        // Task 14: –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ performance services –∏–∑ context
        let cache_manager = ctx.data::<CacheManager>()?;
        let dataloader_manager = ctx.data::<DataLoaderManager>()?;
        let query_analyzer = ctx.data::<QueryComplexityAnalyzer>()?;
        
        // Task 14: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
        let field_complexity = query_analyzer
            .get_field_complexity(&ctx.field().name());
        
        if field_complexity > 50 {
            // –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            return self.resolve_with_aggressive_caching(ctx).await;
        }
        
        // –û–±—ã—á–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å DataLoader
        self.resolve_with_dataloader(ctx).await
    }
    
    async fn resolve_with_dataloader(&self, ctx: &Context<'_>) -> Result<FieldValue> {
        let dataloader_ctx = ctx.data::<DataLoaderContext>()?;
        
        match ctx.field().name() {
            "reviews" => {
                let offer_id = ctx.parent_value.get_offer_id()?;
                let reviews = dataloader_ctx.review_loader
                    .load_by_offer_id(offer_id)
                    .await?;
                Ok(FieldValue::List(reviews))
            }
            "author" => {
                let user_id = ctx.parent_value.get_author_id()?;
                let user = dataloader_ctx.user_loader
                    .load(user_id)
                    .await?;
                Ok(FieldValue::Object(user))
            }
            _ => self.resolve_default(ctx).await
        }
    }
}
```

### 3. Cache ‚Üî Database Integration

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: Cache-through pattern
impl CacheManager {
    pub async fn get_or_fetch<T, F>(&self, 
        cache_key: &str,
        fetch_fn: F,
        ttl: Duration
    ) -> Result<T>
    where
        T: Serialize + DeserializeOwned + Clone + Send + 'static,
        F: FnOnce() -> BoxFuture<'static, Result<T>> + Send
    {
        // Task 14: Multi-level cache check
        if let Some(value) = self.get_from_memory(cache_key).await? {
            self.metrics.record_cache_hit("memory");
            return Ok(value);
        }
        
        if let Some(value) = self.get_from_redis(cache_key).await? {
            self.metrics.record_cache_hit("redis");
            // Populate memory cache
            self.set_memory(cache_key, &value, ttl).await?;
            return Ok(value);
        }
        
        // Cache miss - fetch from source
        self.metrics.record_cache_miss("all");
        let value = fetch_fn().await?;
        
        // Task 14: Write-through caching
        tokio::try_join!(
            self.set_memory(cache_key, &value, ttl),
            self.set_redis(cache_key, &value, ttl)
        )?;
        
        Ok(value)
    }
}
```

## üìä Performance Characteristics

### Container-Level Metrics

```rust
// –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: Container metrics
pub struct ContainerMetrics {
    // GraphQL Server metrics
    pub graphql_requests_total: Counter,
    pub graphql_request_duration: Histogram,
    pub graphql_errors_total: Counter,
    
    // DataLoader metrics
    pub dataloader_batch_size: Histogram,
    pub dataloader_cache_hit_ratio: Gauge,
    pub dataloader_load_duration: Histogram,
    
    // Cache Service metrics
    pub cache_operations_total: Counter,
    pub cache_hit_ratio: Gauge,
    pub cache_size_bytes: Gauge,
    
    // Query Analyzer metrics
    pub query_complexity_score: Histogram,
    pub query_depth: Histogram,
    pub rejected_queries_total: Counter,
    
    // Rate Limiter metrics
    pub rate_limit_checks_total: Counter,
    pub rate_limited_requests_total: Counter,
}
```

### Resource Allocation

```yaml
# –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: docker-compose.yml
version: '3.8'
services:
  ugc-subgraph:
    # Task 14: Resource limits –¥–ª—è optimal performance
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      # Task 14: Performance tuning
      RUST_LOG: info
      DATABASE_MAX_CONNECTIONS: 20
      REDIS_MAX_CONNECTIONS: 10
      DATALOADER_MAX_BATCH_SIZE: 50
      CACHE_MAX_MEMORY_SIZE: 1073741824  # 1GB
      
  redis:
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    command: >
      redis-server 
      --maxmemory 1gb 
      --maxmemory-policy allkeys-lru
      --save 900 1
      
  postgres:
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    environment:
      # Task 14: PostgreSQL performance tuning
      POSTGRES_SHARED_BUFFERS: 512MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 2GB
      POSTGRES_WORK_MEM: 16MB
```

## üîó –°–≤—è–∑—å —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π

–≠—Ç–∞ Container –¥–∏–∞–≥—Ä–∞–º–º–∞ –Ω–∞–ø—Ä—è–º—É—é –æ—Ç—Ä–∞–∂–∞–µ—Ç—Å—è –≤:

- **`src/main.rs`** - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
- **`src/service/`** - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
- **`docker-compose.yml`** - Deployment –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- **`Cargo.toml`** - Dependencies –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
- **`migrations/`** - Database schema optimizations

–î–∏–∞–≥—Ä–∞–º–º–∞ —Å–ª—É–∂–∏—Ç **deployment blueprint** –¥–ª—è Task 14, –ø–æ–∫–∞–∑—ã–≤–∞—è –∫–∞–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—Ç –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º.