@startuml Task9_Code_Diagram
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Component.puml

title Auto.ru Federation - Code Diagram (Task 9: Performance Optimization Implementation)

System_Boundary(caching_implementation, "Caching Implementation") {
    
    System_Boundary(redis_cache_impl, "Redis Cache Implementation") {
        Component(cache_config_impl, "CacheConfig", "Rust Struct", "pub struct CacheConfig {\n    pub redis_url: String,\n    pub default_ttl: Duration,\n    pub max_connections: u32,\n    pub cluster_mode: bool,\n    pub compression: bool,\n}\n\nimpl Default for CacheConfig {\n    fn default() -> Self {\n        Self {\n            redis_url: env!(\"REDIS_URL\").to_string(),\n            default_ttl: Duration::from_secs(300),\n            max_connections: 10,\n            cluster_mode: false,\n            compression: true,\n        }\n    }\n}")
        
        Component(cache_service_impl, "CacheService", "Rust Struct", "pub struct CacheService {\n    client: redis::Client,\n    config: CacheConfig,\n    serializer: Arc<CacheSerializer>,\n}\n\nimpl CacheService {\n    pub async fn get<T>(&self, key: &str) -> Result<Option<T>, CacheError>\n    where T: DeserializeOwned {\n        let mut conn = self.client.get_async_connection().await?;\n        let data: Option<Vec<u8>> = conn.get(key).await?;\n        \n        match data {\n            Some(bytes) => {\n                let value = self.serializer.deserialize(&bytes)?;\n                Ok(Some(value))\n            }\n            None => Ok(None),\n        }\n    }\n    \n    pub async fn set<T>(&self, key: &str, value: &T, ttl: Option<Duration>) -> Result<(), CacheError>\n    where T: Serialize {\n        let bytes = self.serializer.serialize(value)?;\n        let mut conn = self.client.get_async_connection().await?;\n        \n        match ttl.or(Some(self.config.default_ttl)) {\n            Some(duration) => conn.setex(key, duration.as_secs(), bytes).await?,\n            None => conn.set(key, bytes).await?,\n        }\n        \n        Ok(())\n    }\n}")
        
        Component(cache_key_impl, "CacheKeyBuilder", "Rust Struct", "pub struct CacheKeyBuilder;\n\nimpl CacheKeyBuilder {\n    pub fn query_key(query: &str, variables: &serde_json::Value, user_id: Option<Uuid>) -> String {\n        let mut hasher = DefaultHasher::new();\n        query.hash(&mut hasher);\n        variables.to_string().hash(&mut hasher);\n        \n        if let Some(uid) = user_id {\n            uid.hash(&mut hasher);\n        }\n        \n        format!(\"query:{}:{:x}\", \n            if user_id.is_some() { \"user\" } else { \"public\" },\n            hasher.finish()\n        )\n    }\n    \n    pub fn aggregation_key(entity_type: &str, entity_id: Uuid, metric: &str) -> String {\n        format!(\"agg:{}:{}:{}\", entity_type, entity_id, metric)\n    }\n    \n    pub fn session_key(user_id: Uuid, session_type: &str) -> String {\n        format!(\"session:{}:{}\", user_id, session_type)\n    }\n}")
    }
    
    System_Boundary(dataloader_impl, "DataLoader Implementation") {
        Component(review_dataloader_impl, "ReviewDataLoader", "Rust Implementation", "pub struct ReviewDataLoader {\n    db_pool: PgPool,\n    cache: Arc<CacheService>,\n}\n\nimpl ReviewDataLoader {\n    pub fn new(db_pool: PgPool, cache: Arc<CacheService>) -> Self {\n        Self { db_pool, cache }\n    }\n}\n\n#[async_trait]\nimpl Loader<Uuid> for ReviewDataLoader {\n    type Value = Review;\n    type Error = DataLoaderError;\n    \n    async fn load(&self, keys: &[Uuid]) -> Result<HashMap<Uuid, Self::Value>, Self::Error> {\n        // Check cache first\n        let mut results = HashMap::new();\n        let mut missing_keys = Vec::new();\n        \n        for &key in keys {\n            let cache_key = CacheKeyBuilder::entity_key(\"review\", key);\n            if let Ok(Some(review)) = self.cache.get::<Review>(&cache_key).await {\n                results.insert(key, review);\n            } else {\n                missing_keys.push(key);\n            }\n        }\n        \n        // Batch load missing data\n        if !missing_keys.is_empty() {\n            let reviews = sqlx::query_as::<_, Review>(\n                \"SELECT * FROM reviews WHERE id = ANY($1)\"\n            )\n            .bind(&missing_keys)\n            .fetch_all(&self.db_pool)\n            .await?;\n            \n            // Cache and add to results\n            for review in reviews {\n                let cache_key = CacheKeyBuilder::entity_key(\"review\", review.id);\n                let _ = self.cache.set(&cache_key, &review, Some(Duration::from_secs(600))).await;\n                results.insert(review.id, review);\n            }\n        }\n        \n        Ok(results)\n    }\n}")
        
        Component(batch_loader_impl, "BatchLoader", "Rust Generic", "pub struct BatchLoader<K, V> {\n    loader_fn: Arc<dyn Fn(Vec<K>) -> BoxFuture<'static, Result<HashMap<K, V>, LoaderError>> + Send + Sync>,\n    batch_size: usize,\n    delay: Duration,\n}\n\nimpl<K, V> BatchLoader<K, V>\nwhere\n    K: Hash + Eq + Clone + Send + Sync + 'static,\n    V: Clone + Send + Sync + 'static,\n{\n    pub fn new<F, Fut>(loader_fn: F, batch_size: usize, delay: Duration) -> Self\n    where\n        F: Fn(Vec<K>) -> Fut + Send + Sync + 'static,\n        Fut: Future<Output = Result<HashMap<K, V>, LoaderError>> + Send + 'static,\n    {\n        Self {\n            loader_fn: Arc::new(move |keys| Box::pin(loader_fn(keys))),\n            batch_size,\n            delay,\n        }\n    }\n    \n    pub async fn load(&self, key: K) -> Result<Option<V>, LoaderError> {\n        self.load_many(vec![key]).await.map(|mut results| results.remove(&key).flatten())\n    }\n    \n    pub async fn load_many(&self, keys: Vec<K>) -> Result<HashMap<K, Option<V>>, LoaderError> {\n        let chunks: Vec<_> = keys.chunks(self.batch_size).collect();\n        let mut all_results = HashMap::new();\n        \n        for chunk in chunks {\n            tokio::time::sleep(self.delay).await;\n            let results = (self.loader_fn)(chunk.to_vec()).await?;\n            \n            for key in chunk {\n                all_results.insert(key.clone(), results.get(key).cloned());\n            }\n        }\n        \n        Ok(all_results)\n    }\n}")
    }
    
    System_Boundary(rate_limiting_impl, "Rate Limiting Implementation") {
        Component(rate_limiter_impl, "RateLimiter", "Rust Struct", "pub struct RateLimiter {\n    redis: Arc<CacheService>,\n    config: RateLimitConfig,\n}\n\n#[derive(Clone)]\npub struct RateLimitConfig {\n    pub requests_per_minute: u32,\n    pub burst_size: u32,\n    pub window_size: Duration,\n}\n\nimpl RateLimiter {\n    pub async fn check_rate_limit(&self, user_id: Uuid, complexity: f64) -> Result<bool, RateLimitError> {\n        let key = format!(\"rate_limit:{}:{}\", user_id, chrono::Utc::now().minute());\n        let current_requests: u32 = self.redis.get(&key).await?.unwrap_or(0);\n        \n        let complexity_factor = (complexity / 10.0).max(1.0) as u32;\n        let effective_limit = self.config.requests_per_minute / complexity_factor;\n        \n        if current_requests >= effective_limit {\n            return Ok(false);\n        }\n        \n        let new_count = current_requests + 1;\n        self.redis.set(&key, &new_count, Some(Duration::from_secs(60))).await?;\n        \n        Ok(true)\n    }\n}")
        
        Component(query_complexity_impl, "QueryComplexityAnalyzer", "Rust Implementation", "pub struct QueryComplexityAnalyzer {\n    max_depth: usize,\n    max_complexity: f64,\n    field_weights: HashMap<String, f64>,\n}\n\nimpl QueryComplexityAnalyzer {\n    pub fn analyze(&self, query: &str) -> Result<ComplexityResult, AnalysisError> {\n        let document = parse_query(query)?;\n        let mut complexity = 0.0;\n        let mut depth = 0;\n        \n        for definition in document.definitions {\n            if let Definition::OperationDefinition(op) = definition {\n                let (op_complexity, op_depth) = self.analyze_selection_set(&op.selection_set, 1)?;\n                complexity += op_complexity;\n                depth = depth.max(op_depth);\n            }\n        }\n        \n        Ok(ComplexityResult {\n            complexity,\n            depth,\n            is_valid: complexity <= self.max_complexity && depth <= self.max_depth,\n        })\n    }\n    \n    fn analyze_selection_set(&self, selection_set: &SelectionSet, current_depth: usize) -> Result<(f64, usize), AnalysisError> {\n        let mut complexity = 0.0;\n        let mut max_depth = current_depth;\n        \n        for selection in &selection_set.items {\n            match selection {\n                Selection::Field(field) => {\n                    let field_weight = self.field_weights.get(field.name.as_str()).unwrap_or(&1.0);\n                    complexity += field_weight;\n                    \n                    if !field.selection_set.items.is_empty() {\n                        let (nested_complexity, nested_depth) = self.analyze_selection_set(&field.selection_set, current_depth + 1)?;\n                        complexity += nested_complexity;\n                        max_depth = max_depth.max(nested_depth);\n                    }\n                }\n                Selection::InlineFragment(fragment) => {\n                    let (fragment_complexity, fragment_depth) = self.analyze_selection_set(&fragment.selection_set, current_depth)?;\n                    complexity += fragment_complexity;\n                    max_depth = max_depth.max(fragment_depth);\n                }\n                _ => {}\n            }\n        }\n        \n        Ok((complexity, max_depth))\n    }\n}")
    }
    
    System_Boundary(performance_monitoring_impl, "Performance Monitoring Implementation") {
        Component(performance_metrics_impl, "PerformanceMetrics", "Rust Struct", "pub struct PerformanceMetrics {\n    // Cache metrics\n    pub cache_hits: IntCounter,\n    pub cache_misses: IntCounter,\n    pub cache_size: IntGauge,\n    pub cache_evictions: IntCounter,\n    \n    // DataLoader metrics\n    pub dataloader_batch_size: Histogram,\n    pub dataloader_load_time: Histogram,\n    pub n_plus_one_prevented: IntCounter,\n    \n    // Query performance\n    pub query_complexity: Histogram,\n    pub query_depth: Histogram,\n    pub query_execution_time: Histogram,\n    \n    // Rate limiting\n    pub rate_limit_hits: IntCounter,\n    pub rate_limit_violations: IntCounter,\n}\n\nimpl PerformanceMetrics {\n    pub fn record_cache_hit(&self, cache_type: &str) {\n        self.cache_hits.with_label_values(&[cache_type]).inc();\n    }\n    \n    pub fn record_dataloader_batch(&self, loader_type: &str, batch_size: usize, duration: Duration) {\n        self.dataloader_batch_size.with_label_values(&[loader_type]).observe(batch_size as f64);\n        self.dataloader_load_time.with_label_values(&[loader_type]).observe(duration.as_secs_f64());\n    }\n    \n    pub fn record_query_analysis(&self, complexity: f64, depth: usize, execution_time: Duration) {\n        self.query_complexity.observe(complexity);\n        self.query_depth.observe(depth as f64);\n        self.query_execution_time.observe(execution_time.as_secs_f64());\n    }\n}")
        
        Component(cache_invalidator_impl, "CacheInvalidator", "Rust Event System", "pub struct CacheInvalidator {\n    cache: Arc<CacheService>,\n    event_bus: Arc<EventBus>,\n    invalidation_rules: HashMap<String, Vec<InvalidationRule>>,\n}\n\n#[derive(Clone)]\npub struct InvalidationRule {\n    pub pattern: String,\n    pub cascade: bool,\n    pub delay: Option<Duration>,\n}\n\nimpl CacheInvalidator {\n    pub async fn invalidate_by_pattern(&self, pattern: &str) -> Result<u32, InvalidationError> {\n        let keys = self.cache.scan_keys(pattern).await?;\n        let mut invalidated = 0;\n        \n        for key in keys {\n            if let Ok(_) = self.cache.delete(&key).await {\n                invalidated += 1;\n            }\n        }\n        \n        // Trigger cascade invalidation\n        if let Some(rules) = self.invalidation_rules.get(pattern) {\n            for rule in rules {\n                if rule.cascade {\n                    if let Some(delay) = rule.delay {\n                        tokio::time::sleep(delay).await;\n                    }\n                    invalidated += self.invalidate_by_pattern(&rule.pattern).await?;\n                }\n            }\n        }\n        \n        Ok(invalidated)\n    }\n    \n    pub async fn handle_data_change(&self, entity_type: &str, entity_id: Uuid, change_type: ChangeType) -> Result<(), InvalidationError> {\n        match change_type {\n            ChangeType::Create | ChangeType::Update => {\n                // Invalidate entity cache\n                let entity_key = CacheKeyBuilder::entity_key(entity_type, entity_id);\n                self.cache.delete(&entity_key).await?;\n                \n                // Invalidate related aggregations\n                let agg_pattern = format!(\"agg:{}:{}:*\", entity_type, entity_id);\n                self.invalidate_by_pattern(&agg_pattern).await?;\n                \n                // Invalidate query caches that might include this entity\n                let query_pattern = format!(\"query:*:{}:*\", entity_type);\n                self.invalidate_by_pattern(&query_pattern).await?;\n            }\n            ChangeType::Delete => {\n                // Full invalidation for deletions\n                let full_pattern = format!(\"*:{}:{}*\", entity_type, entity_id);\n                self.invalidate_by_pattern(&full_pattern).await?;\n            }\n        }\n        \n        Ok(())\n    }\n}")
    }
    
    System_Boundary(integration_impl, "Integration Implementation") {
        Component(optimized_resolver_impl, "OptimizedResolver", "Rust GraphQL Implementation", "#[Object]\nimpl Query {\n    #[tracing::instrument(skip(self, ctx))]\n    async fn reviews(\n        &self,\n        ctx: &Context<'_>,\n        offer_id: Uuid,\n        first: Option<i32>,\n        after: Option<String>,\n    ) -> FieldResult<ReviewConnection> {\n        let cache_service = ctx.data::<Arc<CacheService>>()?;\n        let dataloader = ctx.data::<DataLoader<ReviewDataLoader>>()?;\n        let metrics = ctx.data::<Arc<PerformanceMetrics>>()?;\n        \n        let start_time = Instant::now();\n        \n        // Generate cache key\n        let cache_key = CacheKeyBuilder::query_key(\n            &format!(\"reviews_by_offer:{}\", offer_id),\n            &serde_json::json!({ \"first\": first, \"after\": after }),\n            ctx.data::<UserId>().ok().map(|u| u.0)\n        );\n        \n        // Try cache first\n        if let Ok(Some(cached_result)) = cache_service.get::<ReviewConnection>(&cache_key).await {\n            metrics.record_cache_hit(\"query_result\");\n            return Ok(cached_result);\n        }\n        \n        metrics.cache_misses.with_label_values(&[\"query_result\"]).inc();\n        \n        // Load data using DataLoader\n        let reviews = dataloader.load_many(vec![offer_id]).await?;\n        \n        // Apply pagination\n        let connection = self.paginate_reviews(reviews, first, after)?;\n        \n        // Cache result\n        let _ = cache_service.set(&cache_key, &connection, Some(Duration::from_secs(300))).await;\n        \n        // Record metrics\n        let execution_time = start_time.elapsed();\n        metrics.query_execution_time.observe(execution_time.as_secs_f64());\n        \n        Ok(connection)\n    }\n}")
        
        Component(middleware_integration_impl, "PerformanceMiddleware", "Rust Axum Middleware", "pub async fn performance_middleware<B>(\n    State(metrics): State<Arc<PerformanceMetrics>>,\n    State(rate_limiter): State<Arc<RateLimiter>>,\n    State(complexity_analyzer): State<Arc<QueryComplexityAnalyzer>>,\n    mut request: Request<B>,\n    next: Next<B>,\n) -> Result<Response, StatusCode> {\n    let start_time = Instant::now();\n    \n    // Extract user ID and query\n    let user_id = extract_user_id(&request).unwrap_or_else(|| Uuid::new_v4());\n    let query = extract_graphql_query(&request).ok_or(StatusCode::BAD_REQUEST)?;\n    \n    // Analyze query complexity\n    let complexity_result = complexity_analyzer.analyze(&query)\n        .map_err(|_| StatusCode::BAD_REQUEST)?;\n    \n    if !complexity_result.is_valid {\n        metrics.rate_limit_violations.inc();\n        return Err(StatusCode::TOO_MANY_REQUESTS);\n    }\n    \n    // Check rate limits\n    let rate_limit_ok = rate_limiter.check_rate_limit(user_id, complexity_result.complexity).await\n        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n    \n    if !rate_limit_ok {\n        metrics.rate_limit_hits.inc();\n        return Err(StatusCode::TOO_MANY_REQUESTS);\n    }\n    \n    // Process request\n    let response = next.run(request).await;\n    \n    // Record metrics\n    let execution_time = start_time.elapsed();\n    metrics.record_query_analysis(\n        complexity_result.complexity,\n        complexity_result.depth,\n        execution_time\n    );\n    \n    Ok(response)\n}")
    }
}

' Relationships between implementation components
Rel(cache_config_impl, cache_service_impl, "configuration", "struct usage")
Rel(cache_service_impl, cache_key_impl, "key generation", "function calls")

Rel(review_dataloader_impl, cache_service_impl, "cache integration", "caching layer")
Rel(batch_loader_impl, review_dataloader_impl, "batch loading", "loader implementation")

Rel(rate_limiter_impl, cache_service_impl, "rate tracking", "Redis storage")
Rel(query_complexity_impl, rate_limiter_impl, "complexity analysis", "rate calculation")

Rel(performance_metrics_impl, cache_service_impl, "cache metrics", "metrics collection")
Rel(cache_invalidator_impl, cache_service_impl, "cache invalidation", "cache management")

Rel(optimized_resolver_impl, cache_service_impl, "result caching", "cache operations")
Rel(optimized_resolver_impl, review_dataloader_impl, "data loading", "batch loading")
Rel(middleware_integration_impl, rate_limiter_impl, "rate limiting", "request throttling")
Rel(middleware_integration_impl, query_complexity_impl, "complexity check", "query analysis")

SHOW_LEGEND()
@enduml